{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8717,"status":"ok","timestamp":1763927088217,"user":{"displayName":"Aryan Nigam","userId":"10788416352118581168"},"user_tz":-330},"id":"EYCGXLT8OqoC","outputId":"61a98533-ff80-4911-afa4-feabba1066ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","False\n","No GPU\n"]}],"source":["!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5180,"status":"ok","timestamp":1763927608044,"user":{"displayName":"Aryan Nigam","userId":"10788416352118581168"},"user_tz":-330},"id":"eqkEGT1kRpre","outputId":"813a4708-e6c0-4a57-a441-819051f1c9b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","Tesla T4\n"]}],"source":["import torch\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"xl0WVbu0E5xR","outputId":"26988264-c185-4fc3-cbc9-101ee9e19848"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170M/170M [00:04<00:00, 34.4MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 44.7M/44.7M [00:00<00:00, 104MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n","==================================================\n","Epoch 1/15\n","Epoch [1], Step [100/782], Loss: 1.5581\n","Epoch [1], Step [200/782], Loss: 1.3168\n","Epoch [1], Step [300/782], Loss: 1.3361\n","Epoch [1], Step [400/782], Loss: 1.3084\n","Epoch [1], Step [500/782], Loss: 1.0370\n","Epoch [1], Step [600/782], Loss: 1.2292\n","Epoch [1], Step [700/782], Loss: 1.3593\n","Train Epoch 1: Loss: 1.3522, Acc: 53.34%\n","Validation: Loss: 0.8309, Acc: 72.40%\n","✅ Saved Best Model with Acc: 72.40%\n","==================================================\n","Epoch 2/15\n","Epoch [2], Step [100/782], Loss: 0.9954\n","Epoch [2], Step [200/782], Loss: 1.2018\n","Epoch [2], Step [300/782], Loss: 1.0973\n","Epoch [2], Step [400/782], Loss: 1.3184\n","Epoch [2], Step [500/782], Loss: 1.0142\n","Epoch [2], Step [600/782], Loss: 0.9408\n","Epoch [2], Step [700/782], Loss: 1.0479\n","Train Epoch 2: Loss: 1.1762, Acc: 58.88%\n","Validation: Loss: 0.7933, Acc: 72.59%\n","✅ Saved Best Model with Acc: 72.59%\n","==================================================\n","Epoch 3/15\n","Epoch [3], Step [100/782], Loss: 0.9164\n","Epoch [3], Step [200/782], Loss: 1.2756\n","Epoch [3], Step [300/782], Loss: 1.0359\n","Epoch [3], Step [400/782], Loss: 1.3026\n","Epoch [3], Step [500/782], Loss: 1.1057\n","Epoch [3], Step [600/782], Loss: 1.0535\n","Epoch [3], Step [700/782], Loss: 1.0634\n","Train Epoch 3: Loss: 1.1519, Acc: 59.63%\n","Validation: Loss: 0.7580, Acc: 74.03%\n","✅ Saved Best Model with Acc: 74.03%\n","==================================================\n","Epoch 4/15\n","Epoch [4], Step [100/782], Loss: 0.9795\n","Epoch [4], Step [200/782], Loss: 1.0521\n","Epoch [4], Step [300/782], Loss: 1.1048\n","Epoch [4], Step [400/782], Loss: 1.3147\n","Epoch [4], Step [500/782], Loss: 1.2316\n","Epoch [4], Step [600/782], Loss: 0.9822\n","Epoch [4], Step [700/782], Loss: 1.1914\n","Train Epoch 4: Loss: 1.1366, Acc: 60.18%\n","Validation: Loss: 0.7310, Acc: 74.49%\n","✅ Saved Best Model with Acc: 74.49%\n","==================================================\n","Epoch 5/15\n","Epoch [5], Step [100/782], Loss: 1.2573\n","Epoch [5], Step [200/782], Loss: 1.0543\n","Epoch [5], Step [300/782], Loss: 1.2163\n","Epoch [5], Step [400/782], Loss: 1.0406\n","Epoch [5], Step [500/782], Loss: 1.3679\n","Epoch [5], Step [600/782], Loss: 1.2296\n","Epoch [5], Step [700/782], Loss: 1.1865\n","Train Epoch 5: Loss: 1.1314, Acc: 60.42%\n","Validation: Loss: 0.7152, Acc: 75.63%\n","✅ Saved Best Model with Acc: 75.63%\n","==================================================\n","Epoch 6/15\n","Epoch [6], Step [100/782], Loss: 1.3196\n","Epoch [6], Step [200/782], Loss: 0.8400\n","Epoch [6], Step [300/782], Loss: 1.0815\n","Epoch [6], Step [400/782], Loss: 1.0723\n","Epoch [6], Step [500/782], Loss: 0.9558\n","Epoch [6], Step [600/782], Loss: 1.0603\n","Epoch [6], Step [700/782], Loss: 1.3285\n","Train Epoch 6: Loss: 1.1278, Acc: 60.36%\n","Validation: Loss: 0.7320, Acc: 74.89%\n","==================================================\n","Epoch 7/15\n","Epoch [7], Step [100/782], Loss: 1.1807\n","Epoch [7], Step [200/782], Loss: 1.1089\n","Epoch [7], Step [300/782], Loss: 0.9867\n","Epoch [7], Step [400/782], Loss: 1.0279\n","Epoch [7], Step [500/782], Loss: 1.0888\n","Epoch [7], Step [600/782], Loss: 1.0005\n","Epoch [7], Step [700/782], Loss: 1.2898\n","Train Epoch 7: Loss: 1.1162, Acc: 60.86%\n","Validation: Loss: 0.7261, Acc: 74.82%\n","==================================================\n","Epoch 8/15\n","Epoch [8], Step [100/782], Loss: 1.0595\n","Epoch [8], Step [200/782], Loss: 0.9360\n","Epoch [8], Step [300/782], Loss: 1.2117\n","Epoch [8], Step [400/782], Loss: 1.2923\n","Epoch [8], Step [500/782], Loss: 1.1060\n","Epoch [8], Step [600/782], Loss: 0.8465\n","Epoch [8], Step [700/782], Loss: 1.2601\n","Train Epoch 8: Loss: 1.1185, Acc: 60.91%\n","Validation: Loss: 0.7161, Acc: 75.38%\n","==================================================\n","Epoch 9/15\n","Epoch [9], Step [100/782], Loss: 0.9975\n","Epoch [9], Step [200/782], Loss: 1.0147\n","Epoch [9], Step [300/782], Loss: 1.0153\n","Epoch [9], Step [400/782], Loss: 1.0924\n","Epoch [9], Step [500/782], Loss: 1.1591\n","Epoch [9], Step [600/782], Loss: 1.2219\n","Epoch [9], Step [700/782], Loss: 1.0551\n","Train Epoch 9: Loss: 1.1288, Acc: 60.55%\n","Validation: Loss: 0.7061, Acc: 75.33%\n","==================================================\n","Epoch 10/15\n","Epoch [10], Step [100/782], Loss: 1.3145\n","Epoch [10], Step [200/782], Loss: 0.8465\n","Epoch [10], Step [300/782], Loss: 0.9598\n","Epoch [10], Step [400/782], Loss: 1.0358\n","Epoch [10], Step [500/782], Loss: 1.0301\n","Epoch [10], Step [600/782], Loss: 1.1206\n","Epoch [10], Step [700/782], Loss: 1.3187\n","Train Epoch 10: Loss: 1.1192, Acc: 60.98%\n","Validation: Loss: 0.7090, Acc: 75.62%\n","==================================================\n","Epoch 11/15\n","Epoch [11], Step [100/782], Loss: 1.1699\n","Epoch [11], Step [200/782], Loss: 1.3427\n","Epoch [11], Step [300/782], Loss: 1.3443\n","Epoch [11], Step [400/782], Loss: 1.1066\n","Epoch [11], Step [500/782], Loss: 1.4066\n","Epoch [11], Step [600/782], Loss: 0.8686\n","Epoch [11], Step [700/782], Loss: 1.2528\n","Train Epoch 11: Loss: 1.1137, Acc: 60.94%\n","Validation: Loss: 0.7301, Acc: 75.00%\n","==================================================\n","Epoch 12/15\n","Epoch [12], Step [100/782], Loss: 0.9843\n","Epoch [12], Step [200/782], Loss: 1.2267\n","Epoch [12], Step [300/782], Loss: 1.0910\n","Epoch [12], Step [400/782], Loss: 1.2839\n","Epoch [12], Step [500/782], Loss: 0.9667\n","Epoch [12], Step [600/782], Loss: 1.0212\n","Epoch [12], Step [700/782], Loss: 0.9751\n","Train Epoch 12: Loss: 1.1163, Acc: 61.14%\n","Validation: Loss: 0.7125, Acc: 75.13%\n","==================================================\n","Epoch 13/15\n","Epoch [13], Step [100/782], Loss: 0.9167\n","Epoch [13], Step [200/782], Loss: 1.3438\n","Epoch [13], Step [300/782], Loss: 1.1633\n","Epoch [13], Step [400/782], Loss: 1.3783\n","Epoch [13], Step [500/782], Loss: 1.1286\n","Epoch [13], Step [600/782], Loss: 1.3643\n","Epoch [13], Step [700/782], Loss: 0.8013\n","Train Epoch 13: Loss: 1.1180, Acc: 60.79%\n","Validation: Loss: 0.7251, Acc: 74.87%\n","==================================================\n","Epoch 14/15\n","Epoch [14], Step [100/782], Loss: 1.0515\n","Epoch [14], Step [200/782], Loss: 1.0222\n","Epoch [14], Step [300/782], Loss: 1.1210\n","Epoch [14], Step [400/782], Loss: 0.9541\n","Epoch [14], Step [500/782], Loss: 1.2825\n","Epoch [14], Step [600/782], Loss: 0.9194\n","Epoch [14], Step [700/782], Loss: 1.3104\n","Train Epoch 14: Loss: 1.0980, Acc: 61.87%\n","Validation: Loss: 0.7001, Acc: 75.49%\n","==================================================\n","Epoch 15/15\n","Epoch [15], Step [100/782], Loss: 1.2285\n","Epoch [15], Step [200/782], Loss: 1.2043\n","Epoch [15], Step [300/782], Loss: 1.3949\n","Epoch [15], Step [400/782], Loss: 0.9893\n","Epoch [15], Step [500/782], Loss: 1.0982\n","Epoch [15], Step [600/782], Loss: 1.0299\n","Epoch [15], Step [700/782], Loss: 1.0769\n","Train Epoch 15: Loss: 1.0887, Acc: 61.64%\n","Validation: Loss: 0.6975, Acc: 75.73%\n","✅ Saved Best Model with Acc: 75.73%\n","Training finished.\n","Best Validation Accuracy: 75.73%\n","Loaded best model for final evaluation.\n","Validation: Loss: 0.6975, Acc: 75.73%\n","Final Test Accuracy (Best Model): 75.73%\n","Confusion Matrix:\n","[[817  18  20  17  11   2   7   4  72  32]\n"," [ 27 849   3   8   1   2   6   4  19  81]\n"," [ 78   6 624  58  68  32  95  15  14  10]\n"," [ 23  11  46 640  29 108  71  27  25  20]\n"," [ 27   1  49  57 691  20  86  58   8   3]\n"," [  6   5  25 165  29 686  35  38   3   8]\n"," [ 11   2  32  60  20   7 854   7   6   1]\n"," [ 36   8  21  45  59  42  24 736   8  21]\n"," [108  24   9  11   4   0   1   7 807  29]\n"," [ 30  61   1   8   1   0   6   4  20 869]]\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import models\n","\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import os\n","\n","# =========================\n","# 1. Config\n","# =========================\n","BATCH_SIZE = 64\n","NUM_EPOCHS = 15\n","LEARNING_RATE = 1e-3\n","MODEL_PATH = \"resnet18_cifar10.pth\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# =========================\n","# 2. Transforms & Datasets\n","# =========================\n","# For ResNet18 (ImageNet), we use 224x224 and ImageNet normalization\n","transform_train = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225]),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225]),\n","])\n","\n","train_dataset = torchvision.datasets.CIFAR10(\n","    root=\"./data\",\n","    train=True,\n","    download=True,\n","    transform=transform_train\n",")\n","\n","test_dataset = torchvision.datasets.CIFAR10(\n","    root=\"./data\",\n","    train=False,\n","    download=True,\n","    transform=transform_test\n",")\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=2\n",")\n","\n","classes = train_dataset.classes\n","print(\"Classes:\", classes)\n","\n","# =========================\n","# 3. Model Definition (ResNet18 Transfer Learning)\n","# =========================\n","# Handle both newer and older torchvision versions\n","try:\n","    # Newer API\n","    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n","except AttributeError:\n","    # Older API fallback\n","    model = models.resnet18(pretrained=True)\n","\n","# Freeze all layers\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Replace final fully-connected layer for CIFAR-10 (10 classes)\n","in_features = model.fc.in_features\n","model.fc = nn.Linear(in_features, 10)\n","\n","model = model.to(device)\n","print(model)\n","\n","# =========================\n","# 4. Loss, Optimizer, Scheduler\n","# =========================\n","criterion = nn.CrossEntropyLoss()\n","\n","# Only train the final classification layer\n","optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n","\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer,\n","    mode='min',\n","    factor=0.3,\n","    patience=3,\n","    min_lr=1e-6\n",")\n","\n","# =========================\n","# 5. Train & Evaluate Functions\n","# =========================\n","def train_one_epoch(epoch):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        if (batch_idx + 1) % 100 == 0:\n","            print(f\"Epoch [{epoch+1}], Step [{batch_idx+1}/{len(train_loader)}], \"\n","                  f\"Loss: {loss.item():.4f}\")\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_acc = 100.0 * correct / total\n","    print(f\"Train Epoch {epoch+1}: Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n","    return epoch_loss, epoch_acc\n","\n","\n","def evaluate():\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    all_targets = []\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for inputs, targets in test_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            all_targets.extend(targets.cpu().numpy())\n","            all_preds.extend(predicted.cpu().numpy())\n","\n","    epoch_loss = running_loss / len(test_loader.dataset)\n","    epoch_acc = 100.0 * correct / total\n","    print(f\"Validation: Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n","\n","    return epoch_loss, epoch_acc, np.array(all_targets), np.array(all_preds)\n","\n","# =========================\n","# 6. Training Loop with Best Model Saving\n","# =========================\n","best_val_acc = 0.0\n","train_history = []\n","val_history = []\n","\n","for epoch in range(NUM_EPOCHS):\n","    print(\"=\" * 50)\n","    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n","\n","    train_loss, train_acc = train_one_epoch(epoch)\n","    val_loss, val_acc, y_true, y_pred = evaluate()\n","\n","    scheduler.step(val_loss)\n","\n","    train_history.append((train_loss, train_acc))\n","    val_history.append((val_loss, val_acc))\n","\n","    # Save best model\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        torch.save(model.state_dict(), MODEL_PATH)\n","        print(f\"✅ Saved Best Model with Acc: {best_val_acc:.2f}%\")\n","\n","print(\"Training finished.\")\n","print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n","\n","# =========================\n","# 7. Load Best Model & Confusion Matrix\n","# =========================\n","if os.path.exists(MODEL_PATH):\n","    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n","    print(\"Loaded best model for final evaluation.\")\n","    _, final_acc, y_true, y_pred = evaluate()\n","    print(f\"Final Test Accuracy (Best Model): {final_acc:.2f}%\")\n","\n","    cm = confusion_matrix(y_true, y_pred)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","else:\n","    print(\"Best model file not found, skipping final confusion matrix.\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOy+1J2I0OR1Zgwegxa2/45"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}